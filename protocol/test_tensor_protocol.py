#!/usr/bin/env python3
"""
Test script for the tensor-protocol direct streaming implementation.
This demonstrates how to use the protocol for sending tensors directly over QUIC streams.
"""

import asyncio
import numpy as np
import time
from typing import Optional

# Import the generated Python bindings
# Note: This would be generated by UniFFI after compilation
try:
    from tensor_protocol import TensorNode, TensorData, TensorMetadata, create_node
except ImportError:
    print("tensor_protocol module not found. Please build the Rust crate first:")
    print("cd protocol && cargo build --release")
    print("Then run: python -m uniffi_bindgen generate src/tensor_protocol.udl --language python")
    exit(1)


def create_test_tensor(shape=(2, 3), dtype="float32") -> TensorData:
    """Create a test tensor with random data."""
    # Generate random numpy array
    if dtype == "float32":
        np_array = np.random.randn(*shape).astype(np.float32)
    elif dtype == "int64":
        np_array = np.random.randint(0, 100, shape, dtype=np.int64)
    else:
        raise ValueError(f"Unsupported dtype: {dtype}")
    
    # Convert to bytes
    tensor_bytes = np_array.tobytes()
    
    # Create metadata
    metadata = TensorMetadata(
        shape=list(shape),
        dtype=dtype,
        requires_grad=False
    )
    
    # Create tensor data
    return TensorData(metadata=metadata, data=tensor_bytes)


def tensor_data_to_numpy(tensor_data: TensorData) -> np.ndarray:
    """Convert TensorData back to numpy array."""
    dtype = tensor_data.metadata.dtype
    shape = tuple(tensor_data.metadata.shape)
    
    # Convert bytes back to numpy array
    np_array = np.frombuffer(tensor_data.data, dtype=dtype)
    return np_array.reshape(shape)


async def test_direct_streaming():
    """Test direct tensor streaming between two nodes."""
    print("=== Testing Direct Tensor Streaming ===")
    
    # Create two nodes
    print("Creating nodes...")
    node1 = create_node(None)  # Memory-based node
    node2 = create_node(None)  # Memory-based node
    
    try:
        # Start both nodes
        print("Starting nodes...")
        await node1.start()
        await node2.start()
        
        # Get node addresses
        addr1 = await node1.get_node_addr()
        addr2 = await node2.get_node_addr()
        print(f"Node 1 address: {addr1}")
        print(f"Node 2 address: {addr2}")
        
        # Create test tensor
        print("Creating test tensor...")
        test_tensor = create_test_tensor(shape=(3, 4), dtype="float32")
        original_array = tensor_data_to_numpy(test_tensor)
        print(f"Original tensor shape: {original_array.shape}")
        print(f"Original tensor data: {original_array}")
        
        # Register tensor on node1
        print("Registering tensor on node1...")
        node1.register_tensor("test_tensor", test_tensor)
        
        # Send tensor from node1 to node2
        print("Sending tensor from node1 to node2...")
        start_time = time.time()
        await node1.send_tensor_direct(addr2, "test_tensor", test_tensor)
        
        # Wait a bit for the tensor to be received
        await asyncio.sleep(0.1)
        
        # Try to receive tensor on node2
        print("Attempting to receive tensor on node2...")
        received_tensor = await node2.receive_tensor()
        
        if received_tensor:
            end_time = time.time()
            transfer_time = end_time - start_time
            
            # Convert back to numpy and verify
            received_array = tensor_data_to_numpy(received_tensor)
            print(f"Received tensor shape: {received_array.shape}")
            print(f"Received tensor data: {received_array}")
            print(f"Transfer time: {transfer_time:.3f} seconds")
            
            # Verify data integrity
            if np.array_equal(original_array, received_array):
                print("✅ SUCCESS: Tensor data matches!")
            else:
                print("❌ ERROR: Tensor data mismatch!")
                print(f"Difference: {np.max(np.abs(original_array - received_array))}")
        else:
            print("❌ ERROR: No tensor received!")
            
    except Exception as e:
        print(f"❌ ERROR: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Cleanup
        print("Shutting down nodes...")
        node1.shutdown()
        node2.shutdown()


async def test_large_tensor():
    """Test streaming of a larger tensor."""
    print("\n=== Testing Large Tensor Streaming ===")
    
    node1 = create_node(None)
    node2 = create_node(None)
    
    try:
        await node1.start()
        await node2.start()
        
        addr1 = await node1.get_node_addr()
        addr2 = await node2.get_node_addr()
        
        # Create a larger tensor (1MB)
        shape = (256, 256)  # 256KB for float32
        large_tensor = create_test_tensor(shape=shape, dtype="float32")
        tensor_size = len(large_tensor.data)
        print(f"Large tensor size: {tensor_size / 1024:.1f} KB")
        
        # Send large tensor
        start_time = time.time()
        await node1.send_tensor_direct(addr2, "large_tensor", large_tensor)
        
        await asyncio.sleep(0.2)  # Give more time for large transfer
        
        received_tensor = await node2.receive_tensor()
        
        if received_tensor:
            end_time = time.time()
            transfer_time = end_time - start_time
            throughput = (tensor_size / 1024) / transfer_time  # KB/s
            
            print(f"✅ Large tensor received successfully!")
            print(f"Transfer time: {transfer_time:.3f} seconds")
            print(f"Throughput: {throughput:.1f} KB/s")
        else:
            print("❌ Large tensor not received!")
            
    except Exception as e:
        print(f"❌ ERROR in large tensor test: {e}")
    
    finally:
        node1.shutdown()
        node2.shutdown()


async def main():
    """Main test function."""
    print("Tensor Protocol Direct Streaming Test")
    print("=====================================")
    
    # Run tests
    await test_direct_streaming()
    await test_large_tensor()
    
    print("\n=== Test Complete ===")


if __name__ == "__main__":
    # Set up logging
    import logging
    logging.basicConfig(level=logging.INFO)
    
    # Run the test
    asyncio.run(main()) 