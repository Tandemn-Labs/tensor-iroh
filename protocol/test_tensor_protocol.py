#!/usr/bin/env python3
"""
Test script for the tensor-protocol direct streaming implementation.
This demonstrates how to use the protocol for sending tensors directly over QUIC streams.

Updated to use the new NodeTicket format that includes both relay URLs and direct addresses.
"""

import asyncio
import time
import struct
from typing import Optional

# Import the generated Python bindings
# Note: This would be generated by UniFFI after compilation
try:
    from tensor_protocol import TensorNode, TensorData, TensorMetadata, create_node
except ImportError:
    print("tensor_protocol module not found. Please build the Rust crate first:")
    print("cd protocol && cargo build --release")
    print("Then run the build_and_test.sh script to generate Python bindings")
    exit(1)


def create_test_tensor_deterministic(shape=(3, 4), dtype="float32") -> TensorData:
    """Create a deterministic test tensor (matches the Rust test exactly)."""
    if dtype != "float32":
        raise ValueError("Only float32 supported in this test")
    
    # Create deterministic data exactly like the Rust test
    num_elems = shape[0] * shape[1]
    tensor_bytes = bytearray()
    
    for i in range(num_elems):
        # Convert i to f32 and get little-endian bytes (matches Rust to_ne_bytes())
        float_val = float(i)
        # Use struct.pack to convert float to 4 bytes (little-endian)
        float_bytes = struct.pack('<f', float_val)
        tensor_bytes.extend(float_bytes)
    
    # Create metadata
    metadata = TensorMetadata(
        shape=list(shape),
        dtype=dtype,
        requires_grad=False
    )
    
    # Create tensor data
    return TensorData(metadata=metadata, data=bytes(tensor_bytes))


def create_test_tensor_random(shape=(2, 3), dtype="float32") -> TensorData:
    """Create a test tensor with random-like data (no numpy dependency)."""
    if dtype == "float32":
        # Generate simple test data without numpy
        import random
        tensor_bytes = bytearray()
        for i in range(shape[0] * shape[1]):
            # Create some deterministic but varied float values
            val = float(i + random.randint(1, 100) * 0.1)
            # Use struct.pack to convert float to 4 bytes (little-endian)
            float_bytes = struct.pack('<f', val)
            tensor_bytes.extend(float_bytes)
    else:
        raise ValueError(f"Unsupported dtype: {dtype}")
    
    # Create metadata
    metadata = TensorMetadata(
        shape=list(shape),
        dtype=dtype,
        requires_grad=False
    )
    
    # Create tensor data
    return TensorData(metadata=metadata, data=bytes(tensor_bytes))


def compare_tensor_data(tensor1: TensorData, tensor2: TensorData) -> bool:
    """Compare two TensorData objects for equality."""
    # Compare metadata
    if (tensor1.metadata.shape != tensor2.metadata.shape or
        tensor1.metadata.dtype != tensor2.metadata.dtype or
        tensor1.metadata.requires_grad != tensor2.metadata.requires_grad):
        return False
    
    # Compare data bytes
    return tensor1.data == tensor2.data


async def test_direct_streaming():
    """Test direct tensor streaming between two nodes (matches Rust test)."""
    print("=== Testing Direct Tensor Streaming ===")
    
    # Create two nodes
    print("Creating nodes...")
    node1 = create_node(None)  # Memory-based node
    node2 = create_node(None)  # Memory-based node
    
    try:
        # Start both nodes
        print("Starting nodes...")
        await node1.start()
        await node2.start()
        
        # Get node addresses (now returns NodeTickets!)
        addr1 = await node1.get_node_addr()
        addr2 = await node2.get_node_addr()
        print(f"Node1 NodeTicket: {addr1}")
        print(f"Node2 NodeTicket: {addr2}")
        
        # Create test tensor (exactly like Rust test)
        print("Creating test tensor...")
        test_tensor = create_test_tensor_deterministic(shape=(3, 4), dtype="float32")
        print(f"Created test tensor of {len(test_tensor.data)} bytes")
        print(f"Tensor shape: {test_tensor.metadata.shape}")
        print(f"Tensor dtype: {test_tensor.metadata.dtype}")
        
        # Register tensor on node1
        print("Registering tensor on node1...")
        node1.register_tensor("test_tensor", test_tensor)
        
        # Send tensor from node1 to node2 using NodeTicket
        print("Sending tensor from node1 to node2...")
        start_time = time.time()
        await node1.send_tensor_direct(addr2, "test_tensor", test_tensor)
        
        # Wait briefly for delivery
        await asyncio.sleep(2)
        
        # Try to receive tensor on node2 (with retry loop like Rust test)
        print("Receiving tensor on node2...")
        received_tensor = None
        for attempt in range(1, 51):  # 1 to 50 attempts like Rust test
            received = await node2.receive_tensor()
            if received:
                received_tensor = received
                print(f"✅ Received on attempt {attempt}")
                break
            await asyncio.sleep(0.05)  # 100ms between attempts
        
        if received_tensor:
            end_time = time.time()
            transfer_time = end_time - start_time
            
            print(f"Received tensor size: {len(received_tensor.data)} bytes")
            print(f"Transfer time: {transfer_time:.3f} seconds")
            
            # Verify data integrity (like Rust test)
            if compare_tensor_data(test_tensor, received_tensor):
                print("✅ SUCCESS: Tensor metadata and data match!")
                return True
            else:
                print("❌ ERROR: Tensor data mismatch!")
                print(f"Original size: {len(test_tensor.data)}, Received size: {len(received_tensor.data)}")
                return False
        else:
            print("❌ ERROR: Failed to receive tensor!")
            return False
            
    except Exception as e:
        print(f"❌ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Cleanup
        print("Shutting down nodes...")
        node1.shutdown()
        node2.shutdown()


async def test_larger_tensor():
    """Test streaming of a larger tensor to verify the protocol works with bigger data."""
    print("\n=== Testing Larger Tensor Streaming ===")
    
    node1 = create_node(None)
    node2 = create_node(None)
    
    try:
        await node1.start()
        await node2.start()
        
        addr1 = await node1.get_node_addr()
        addr2 = await node2.get_node_addr()
        
        # Create a larger tensor
        shape = (64, 64)  # 16KB for float32
        large_tensor = create_test_tensor_random(shape=shape, dtype="float32")
        tensor_size = len(large_tensor.data)
        print(f"Large tensor size: {tensor_size / 1024:.1f} KB")
        
        # Register and send large tensor
        node1.register_tensor("large_tensor", large_tensor)
        
        start_time = time.time()
        await node1.send_tensor_direct(addr2, "large_tensor", large_tensor)
        
        await asyncio.sleep(0.2)  # Give more time for large transfer
        
        # Try to receive with more attempts for larger tensor
        received_tensor = None
        for attempt in range(1, 100):  # More attempts for larger data
            received = await node2.receive_tensor()
            if received:
                received_tensor = received
                print(f"✅ Large tensor received on attempt {attempt}")
                break
            await asyncio.sleep(0.05)  # Faster polling for large tensor
        
        if received_tensor:
            end_time = time.time()
            transfer_time = end_time - start_time
            throughput = (tensor_size / 1024) / transfer_time  # KB/s
            
            if compare_tensor_data(large_tensor, received_tensor):
                print(f"✅ Large tensor data integrity verified!")
                print(f"Transfer time: {transfer_time:.3f} seconds")
                print(f"Throughput: {throughput:.1f} KB/s")
                return True
            else:
                print("❌ Large tensor data mismatch!")
                return False
        else:
            print("❌ Large tensor not received!")
            return False
            
    except Exception as e:
        print(f"❌ ERROR in large tensor test: {e}")
        return False
    
    finally:
        node1.shutdown()
        node2.shutdown()


async def test_node_addressing():
    """Test that nodes can get their addressing information correctly."""
    print("\n=== Testing Node Addressing ===")
    
    node = create_node(None)
    
    try:
        await node.start()
        
        # Get the node's address
        addr = await node.get_node_addr()
        print(f"Node address (NodeTicket): {addr}")
        
        # Verify it starts with the expected NodeTicket prefix
        if addr.startswith("node"):
            print("✅ NodeTicket format is correct")
            return True
        else:
            print(f"❌ Unexpected address format: {addr}")
            return False
            
    except Exception as e:
        print(f"❌ ERROR in addressing test: {e}")
        return False
    
    finally:
        node.shutdown()


async def main():
    """Main test function."""
    print("Tensor Protocol Direct Streaming Test")
    print("=====================================")
    print("Updated for NodeTicket format with relay + direct address support")
    print()
    
    # Run tests
    success_count = 0
    total_tests = 3
    
    if await test_node_addressing():
        success_count += 1
        
    if await test_direct_streaming():
        success_count += 1
        
    if await test_larger_tensor():
        success_count += 1
    
    print(f"\n=== Test Results: {success_count}/{total_tests} tests passed ===")
    
    if success_count == total_tests:
        print("🎉 All tests passed! The tensor protocol is working correctly.")
    else:
        print("⚠️  Some tests failed. Check the output above for details.")


if __name__ == "__main__":
    # Set up basic logging
    import logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    # Run the test
    asyncio.run(main()) 